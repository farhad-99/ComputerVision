{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b5288ae",
   "metadata": {},
   "source": [
    "<div align=center>\n",
    "<font face=\"XB Niloofar\">\n",
    "<font size=4>\n",
    "گزارش آزمایش نهم\n",
    "<p></p>\n",
    "<font size=4>\n",
    "فرهاد فلاح 97102214 \n",
    "<p></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0606210f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.cluster import KMeans\n",
    "from tqdm import tqdm\n",
    "from scipy.cluster.vq import vq\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "535e7b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_dict = {'handclapping':0 ,'handwaving':1 ,  'running':2}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec797bbb",
   "metadata": {},
   "source": [
    "نرخ های مختلفی برای نمونه برداری امتحان شد در نرخ 0.1 هم دقت هم سرعت مناسب بود"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "becf6a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 99/99 [00:08<00:00, 11.39it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:10<00:00,  9.17it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:07<00:00, 12.88it/s]\n"
     ]
    }
   ],
   "source": [
    "path = 'Dataset'\n",
    "category = 'handclapping'\n",
    "percentage = 0.1\n",
    "features = []\n",
    "for category in ['handclapping' ,'handwaving',  'running']:\n",
    "    for file in tqdm(os.listdir(f'{path}/{category}')):\n",
    "        Mags = []\n",
    "        Angs = []\n",
    "        #file = 'person01_handclapping_d2_uncomp.avi'\n",
    "        cap = cv2.VideoCapture(f'{path}/{category}/{file}')\n",
    "        l = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        w  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))   \n",
    "        h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "        ret, frame1 = cap.read()\n",
    "        height = int(h * percentage)\n",
    "        width = int(w * percentage)\n",
    "        dim = (width,height)\n",
    "        frame1 = cv2.resize(frame1, dim, interpolation = cv2.INTER_AREA)\n",
    "        prvs = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "        hsv = np.zeros_like(frame1)\n",
    "        while(1):\n",
    "            ret, frame2 = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            frame2 = cv2.resize(frame2, dim, interpolation = cv2.INTER_AREA)\n",
    "            next = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "            flow = cv2.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "            mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "            Mags . append(mag.ravel())\n",
    "            Angs.append(ang.ravel())\n",
    "            prvs = next\n",
    "        Mags = np.array(Mags)\n",
    "        Angs = np.array(Angs)\n",
    "        feature_vec = np.append(Mags,Angs,axis=1)\n",
    "       \n",
    "        features.append(feature_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7c9ff6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "handclapping = features[0:99]\n",
    "handwaving = features[99:199]\n",
    "running = features[199:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f18b2887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np.zeros((80,1))\n",
    "y_train = np.append(y_train,np.ones((80,1)),axis = 0)\n",
    "y_train = np.append(y_train,2*np.ones((80,1)),axis = 0)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d887c603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = handclapping[0:80] +  handwaving[0:80] +  running[0:80]\n",
    "\n",
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "415c6d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = handclapping[80:] +  handwaving[80:] +  running[80:]\n",
    "y_test = np.zeros((19,1))\n",
    "y_test = np.append(y_test , np.ones((20,1)),axis = 0)\n",
    "y_test = np.append(y_test , 2*np.ones((20,1)),axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e437b40d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107968"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features = []\n",
    "n_clusters = 180\n",
    "for video in (train):\n",
    "    features = video\n",
    "    for feature in features:\n",
    "        train_features.append(feature) \n",
    "    \n",
    "len(train_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bd69ba6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=180, n_init=2)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(init='k-means++', n_clusters=n_clusters, n_init=2)\n",
    "kmeans.fit(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "57251716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180, 384)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters = kmeans.cluster_centers_\n",
    "clusters.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3c769126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 180)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow =[]\n",
    "for sample in train:\n",
    "    labels = vq(sample, clusters)[0]\n",
    "    hist = np.histogram(labels,bins = np.arange(n_clusters+1))[0]\n",
    "    bow.append(hist)\n",
    "bow = np.array(bow)   \n",
    "bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "170a2a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(264, 384)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6eb28b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'C': 10.0, 'gamma': 0.001} with a score of 0.89\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = bow\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "\n",
    "\n",
    "\n",
    "svc = SVC(kernel = 'rbf')\n",
    "\n",
    "C_range = np.logspace(-10, 10, 21)\n",
    "gamma_range = np.logspace(-10, 10, 21)\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "#cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "grid = GridSearchCV(svc, param_grid=param_grid)\n",
    "grid.fit(X_train, y_train.ravel())\n",
    "\n",
    "print(\n",
    "    \"The best parameters are %s with a score of %0.2f\"\n",
    "    % (grid.best_params_, grid.best_score_)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4f4fc7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix for training set:\n",
      "[[79  1  0]\n",
      " [ 0 80  0]\n",
      " [ 0  0 80]]\n",
      "accuracy for training set:\n",
      "0.9958333333333333\n"
     ]
    }
   ],
   "source": [
    "C, gamma = grid.best_params_['C'], grid.best_params_['gamma']\n",
    "clf = SVC(C=C, gamma=gamma)\n",
    "clf.fit(X_train, y_train.ravel())\n",
    "y_train_p= clf.predict(X_train)\n",
    "#y_test_p = clf.predict(X_test)\n",
    "\n",
    "print('confusion matrix for training set:')\n",
    "print(confusion_matrix(y_train, y_train_p))\n",
    "print('accuracy for training set:')\n",
    "print(accuracy_score(y_train, y_train_p))\n",
    "#print('\\nconfusion matrix for validation set:')\n",
    "#print(confusion_matrix(y_test, y_test_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e7823e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59, 180)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_test =[]\n",
    "for sample in test:\n",
    "    labels = vq(sample, clusters)[0]\n",
    "    hist = np.histogram(labels,bins = np.arange(n_clusters+1))[0]\n",
    "    bow_test.append(hist)\n",
    "bow_test = np.array(bow_test)   \n",
    "bow_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "71b64eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "confusion matrix for test set:\n",
      "[[16  3  0]\n",
      " [ 6 14  0]\n",
      " [ 0  0 20]]\n",
      "accuracy for test set:\n",
      "0.847457627118644\n"
     ]
    }
   ],
   "source": [
    "X_test = bow_test\n",
    "scaler.fit(X_test)\n",
    "X_test = scaler.transform(X_test)\n",
    "y_test_p = clf.predict(X_test)\n",
    "print('\\nconfusion matrix for test set:')\n",
    "print(confusion_matrix(y_test, y_test_p))\n",
    "print('accuracy for test set:')\n",
    "print(accuracy_score(y_test, y_test_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "692e7b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'C': 10000000.0, 'gamma': 1e-09} with a score of 0.90\n",
      "confusion matrix for training set:\n",
      "[[77  3  0]\n",
      " [ 5 75  0]\n",
      " [ 0  0 80]]\n",
      "accuracy for training set:\n",
      "0.9666666666666667\n",
      "\n",
      "confusion matrix for test set:\n",
      "[[18  1  0]\n",
      " [ 5 15  0]\n",
      " [ 1  0 19]]\n",
      "accuracy for test set:\n",
      "0.8813559322033898\n"
     ]
    }
   ],
   "source": [
    "n_clusters = 200\n",
    "\n",
    "kmeans2 = KMeans(init='k-means++', n_clusters=n_clusters, n_init=2)\n",
    "kmeans2.fit(train_features)\n",
    "\n",
    "clusters2 = kmeans2.cluster_centers_\n",
    "\n",
    "bow =[]\n",
    "for sample in train:\n",
    "    labels = vq(sample, clusters2)[0]\n",
    "    hist = np.histogram(labels,bins = np.arange(n_clusters+1))[0]\n",
    "    bow.append(hist)\n",
    "bow = np.array(bow)   \n",
    "bow.shape\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = bow\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "\n",
    "\n",
    "\n",
    "svc = SVC(kernel = 'rbf')\n",
    "\n",
    "C_range = np.logspace(-10, 10, 21)\n",
    "gamma_range = np.logspace(-10, 10, 21)\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "#cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "grid = GridSearchCV(svc, param_grid=param_grid)\n",
    "grid.fit(X_train, y_train.ravel())\n",
    "\n",
    "print(\n",
    "    \"The best parameters are %s with a score of %0.2f\"\n",
    "    % (grid.best_params_, grid.best_score_)\n",
    ")\n",
    "\n",
    "C, gamma = grid.best_params_['C'], grid.best_params_['gamma']\n",
    "clf2 = SVC(C=C, gamma=gamma)\n",
    "clf2.fit(X_train, y_train.ravel())\n",
    "y_train_p= clf2.predict(X_train)\n",
    "\n",
    "print('confusion matrix for training set:')\n",
    "print(confusion_matrix(y_train, y_train_p))\n",
    "print('accuracy for training set:')\n",
    "print(accuracy_score(y_train, y_train_p))\n",
    "\n",
    "bow_test =[]\n",
    "for sample in test:\n",
    "    labels = vq(sample, clusters2)[0]\n",
    "    hist = np.histogram(labels,bins = np.arange(n_clusters+1))[0]\n",
    "    bow_test.append(hist)\n",
    "bow_test = np.array(bow_test)   \n",
    "\n",
    "X_test = bow_test\n",
    "scaler.fit(X_test)\n",
    "X_test = scaler.transform(X_test)\n",
    "y_test_p = clf2.predict(X_test)\n",
    "print('\\nconfusion matrix for test set:')\n",
    "print(confusion_matrix(y_test, y_test_p))\n",
    "print('accuracy for test set:')\n",
    "print(accuracy_score(y_test, y_test_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "17f2b090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'C': 1000000.0, 'gamma': 1e-09} with a score of 0.90\n",
      "confusion matrix for training set:\n",
      "[[76  4  0]\n",
      " [ 9 71  0]\n",
      " [ 0  0 80]]\n",
      "accuracy for training set:\n",
      "0.9458333333333333\n",
      "\n",
      "confusion matrix for test set:\n",
      "[[19  0  0]\n",
      " [ 6 14  0]\n",
      " [ 0  0 20]]\n",
      "accuracy for test set:\n",
      "0.8983050847457628\n"
     ]
    }
   ],
   "source": [
    "n_clusters = 220\n",
    "\n",
    "kmeans3 = KMeans(init='k-means++', n_clusters=n_clusters, n_init=2)\n",
    "kmeans3.fit(train_features)\n",
    "\n",
    "clusters3 = kmeans3.cluster_centers_\n",
    "\n",
    "\n",
    "bow =[]\n",
    "for sample in train:\n",
    "    labels = vq(sample, clusters3)[0]\n",
    "    hist = np.histogram(labels,bins = np.arange(n_clusters+1))[0]\n",
    "    bow.append(hist)\n",
    "bow = np.array(bow)   \n",
    "bow.shape\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = bow\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "\n",
    "\n",
    "\n",
    "svc = SVC(kernel = 'rbf')\n",
    "\n",
    "C_range = np.logspace(-10, 10, 21)\n",
    "gamma_range = np.logspace(-10, 10, 21)\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "#cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "grid = GridSearchCV(svc, param_grid=param_grid)\n",
    "grid.fit(X_train, y_train.ravel())\n",
    "\n",
    "print(\n",
    "    \"The best parameters are %s with a score of %0.2f\"\n",
    "    % (grid.best_params_, grid.best_score_)\n",
    ")\n",
    "\n",
    "C, gamma = grid.best_params_['C'], grid.best_params_['gamma']\n",
    "clf3 = SVC(C=C, gamma=gamma)\n",
    "clf3.fit(X_train, y_train.ravel())\n",
    "y_train_p= clf3.predict(X_train)\n",
    "\n",
    "print('confusion matrix for training set:')\n",
    "print(confusion_matrix(y_train, y_train_p))\n",
    "print('accuracy for training set:')\n",
    "print(accuracy_score(y_train, y_train_p))\n",
    "\n",
    "bow_test =[]\n",
    "for sample in test:\n",
    "    labels = vq(sample, clusters3)[0]\n",
    "    hist = np.histogram(labels,bins = np.arange(n_clusters+1))[0]\n",
    "    bow_test.append(hist)\n",
    "bow_test = np.array(bow_test)   \n",
    "\n",
    "X_test = bow_test\n",
    "scaler.fit(X_test)\n",
    "X_test = scaler.transform(X_test)\n",
    "y_test_p = clf3.predict(X_test)\n",
    "print('\\nconfusion matrix for test set:')\n",
    "print(confusion_matrix(y_test, y_test_p))\n",
    "print('accuracy for test set:')\n",
    "print(accuracy_score(y_test, y_test_p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3dbeca",
   "metadata": {},
   "source": [
    "همانطور که مشاهده میشود با افزایش بین ها دقت اموزش کم شده(اور فیت کمتر میشود)ولی دقت تست ما بهتر میگردد."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bfd23d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "13ebcedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181 640 826\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(180, 384)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('test1.mp4')\n",
    "l = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "w  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))   \n",
    "h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "print(l,w,h)\n",
    "Mags = []\n",
    "Angs = []\n",
    "ret, frame1 = cap.read()\n",
    "height = int(h * percentage)\n",
    "width = int(w * percentage)\n",
    "dim = (16,12)\n",
    "frame1 = cv2.resize(frame1, dim, interpolation = cv2.INTER_AREA)\n",
    "prvs = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "hsv = np.zeros_like(frame1)\n",
    "hsv[..., 1] = 255\n",
    "while(1):\n",
    "    ret, frame2 = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame2 = cv2.resize(frame2, dim, interpolation = cv2.INTER_AREA)\n",
    "    next = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    flow = cv2.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    Mags . append(mag.ravel())\n",
    "    Angs.append(ang.ravel())\n",
    "    \n",
    "    prvs = next\n",
    "Mags = np.array(Mags)\n",
    "Angs = np.array(Angs)\n",
    "feature_vec = np.append(Mags,Angs,axis=1)\n",
    "feature_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "35871b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1.])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_testt = []\n",
    "n_clusters = 220\n",
    "labels = vq(feature_vec, clusters3)[0]\n",
    "hist = np.histogram(labels,bins = np.arange(n_clusters+1))[0]\n",
    "bow_testt.append(hist)\n",
    "bow_testt.append(hist)\n",
    "bow_testt = np.array(bow_testt)   \n",
    "X_test = bow_testt\n",
    "y_pred = clf3.predict(X_test)\n",
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
